from flask import Blueprint, jsonify, request
from models.news_models import NewsModel
from services.news_service import NewsService
from datetime import datetime
import pytz
from config import Config
import logging

logger = logging.getLogger(__name__)

news_bp = Blueprint("news", __name__, url_prefix="/api/news")


# ============================================================
# ğŸ¯ YENÄ°: SADECE SCRAPE EDÄ°LMÄ°Å HABERLER (ANDROID Ä°Ã‡Ä°N)
# ============================================================

@news_bp.route("/scraped", methods=["GET"])
def get_scraped_news():
    """
    âœ… SADECE scrape edilmiÅŸ (tam metin) haberleri dÃ¶ndÃ¼r
    Android uygulamasÄ± iÃ§in ASIL endpoint
    
    Query Parameters:
        - limit: KaÃ§ haber (varsayÄ±lan 50, max 200)
        - offset: Pagination (varsayÄ±lan 0)
        - category: Kategori filtresi (opsiyonel)
    
    Response:
        {
            "success": true,
            "count": 45,
            "total_scraped": 120,
            "news": [...]
        }
    """
    try:
        limit = request.args.get('limit', 50, type=int)
        offset = request.args.get('offset', 0, type=int)
        category = request.args.get('category', None, type=str)
        
        # Limit kontrolÃ¼ (max 200)
        if limit > 200:
            limit = 200
        
        # SADECE scrape edilmiÅŸ haberleri getir
        news = NewsModel.get_scraped_only(
            category=category,
            limit=limit,
            offset=offset
        )
        
        # Toplam scrape edilmiÅŸ haber sayÄ±sÄ±
        total_scraped = NewsModel.count_scraped()
        
        logger.info(f"ğŸ“± Android request: {len(news)} scrape edilmiÅŸ haber dÃ¶ndÃ¼rÃ¼ldÃ¼")
        
        return jsonify({
            "success": True,
            "count": len(news),
            "total_scraped": total_scraped,
            "has_more": (offset + len(news)) < total_scraped,
            "news": news
        })
        
    except Exception as e:
        logger.exception("âŒ /scraped endpoint hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/scraped/after", methods=["GET"])
def get_scraped_after():
    """
    âœ… Belirli tarihten sonra scrape edilmiÅŸ haberleri dÃ¶ndÃ¼r
    Android Worker iÃ§in - sadece yeni tam metin haberler
    
    Query Parameters:
        - after: ISO format tarih (zorunlu) - Ã¶rn: 2025-12-08T15:00:00Z
        - limit: KaÃ§ haber (varsayÄ±lan 50, max 200)
        - category: Kategori filtresi (opsiyonel)
    
    Response:
        {
            "success": true,
            "count": 15,
            "news": [...]
        }
    """
    try:
        after = request.args.get('after', type=str)
        limit = request.args.get('limit', 50, type=int)
        category = request.args.get('category', None, type=str)
        
        # 'after' parametresi zorunlu
        if not after:
            return jsonify({
                "success": False,
                "error": "Missing required parameter: 'after' (ISO date)"
            }), 400
        
        # Limit kontrolÃ¼
        if limit > 200:
            limit = 200
        
        # Tarihten sonraki scrape edilmiÅŸ haberleri getir
        news = NewsModel.get_scraped_after(
            after_date=after,
            category=category,
            limit=limit
        )
        
        logger.info(f"ğŸ“± Worker request: {after} sonrasÄ± {len(news)} yeni haber")
        
        return jsonify({
            "success": True,
            "count": len(news),
            "after": after,
            "news": news
        })
        
    except ValueError as e:
        return jsonify({
            "success": False,
            "error": f"Invalid date format: {str(e)}"
        }), 400
    except Exception as e:
        logger.exception("âŒ /scraped/after endpoint hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/scraped/stats", methods=["GET"])
def scraped_stats():
    """
    âœ… Scraping istatistikleri
    
    Response:
        {
            "success": true,
            "scraped": 95,
            "unscraped": 25,
            "blacklisted": 3,
            "total": 120
        }
    """
    try:
        scraped = NewsModel.count_scraped()
        unscraped = NewsModel.count_unscraped()
        blacklisted = NewsModel.get_blacklist_count()
        total = NewsModel.get_total_count()
        
        return jsonify({
            "success": True,
            "scraped": scraped,
            "unscraped": unscraped,
            "blacklisted": blacklisted,
            "total": total,
            "scraping_rate": round((scraped / total * 100) if total > 0 else 0, 1)
        })
        
    except Exception as e:
        logger.exception("âŒ /scraped/stats hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# ============================================================
# ğŸ“± ESKÄ° ENDPOINT'LER (Geriye DÃ¶nÃ¼k Uyumluluk)
# ============================================================

@news_bp.route("/latest", methods=["GET"])
def latest_news():
    """
    âš ï¸ ESKÄ° ENDPOINT - TÃœM haberleri dÃ¶ndÃ¼rÃ¼r (boÅŸ iÃ§erikli dahil)
    Geriye dÃ¶nÃ¼k uyumluluk iÃ§in korundu
    
    âœ… YENÄ°: Android iÃ§in /scraped endpoint'ini kullan
    """
    try:
        limit = request.args.get('limit', 100, type=int)
        offset = request.args.get('offset', 0, type=int)
        
        news = NewsModel.get_news(limit=limit, offset=offset)
        
        return jsonify({
            "success": True,
            "count": len(news),
            "news": news
        })
    except Exception as e:
        logger.exception("âŒ /latest endpoint hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/last-update", methods=["GET"])
def last_update():
    """
    âœ… Sadece son gÃ¼ncelleme zamanÄ±nÄ± dÃ¶ndÃ¼r
    Android Worker iÃ§in hafif kontrol
    """
    try:
        dt = NewsModel.get_latest_update_time()
        
        if not dt:
            return jsonify({
                "success": True,
                "last_update": None,
                "has_data": False
            })
        
        tz = pytz.timezone(Config.TIMEZONE)
        dt_local = dt.astimezone(tz)
        
        return jsonify({
            "success": True,
            "last_update": dt_local.isoformat(),
            "timestamp_unix": int(dt_local.timestamp()),
            "has_data": True
        })
        
    except Exception as e:
        logger.exception("âŒ /last-update hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/update", methods=["POST", "GET"])
def update_news():
    """
    ğŸ”§ Manuel haber gÃ¼ncelleme tetikleyici
    Cron dÄ±ÅŸÄ±nda test/debug iÃ§in kullan
    """
    try:
        stats = NewsService.update_all_categories(api_source="auto")
        
        return jsonify({
            "success": True,
            "message": "Haberler gÃ¼ncellendi.",
            "stats": stats
        })
        
    except Exception as e:
        logger.exception("âŒ /update hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/status", methods=["GET"])
def system_status():
    """
    ğŸ“Š Sistem durumu ve istatistikler
    Monitoring/dashboard iÃ§in
    """
    try:
        status = NewsService.get_system_status()
        
        # datetime objesi varsa isoformat'a Ã§evir
        db_last = status["database"].get("latest_update")
        if isinstance(db_last, datetime):
            status["database"]["latest_update"] = db_last.isoformat()
        
        # Scraping istatistiklerini ekle
        status["scraping"] = {
            "scraped": NewsModel.count_scraped(),
            "unscraped": NewsModel.count_unscraped(),
            "blacklisted": NewsModel.get_blacklist_count()
        }
        
        return jsonify(status)
        
    except Exception as e:
        logger.exception("âŒ /status hatasÄ±")
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@news_bp.route("/health", methods=["GET"])
def health():
    """
    ğŸ’š Basit health check
    Load balancer/monitoring iÃ§in
    """
    return jsonify({
        "success": True,
        "status": "OK"
    })


# ============================================================
# ğŸ”§ YÃ–NETÄ°CÄ° ENDPOINT'LERÄ° (Opsiyonel)
# ============================================================

@news_bp.route("/blacklist", methods=["GET"])
def get_blacklist():
    """
    ğŸš« Blacklist'teki URL'leri listele
    """
    try:
        count = NewsModel.get_blacklist_count()
        
        return jsonify({
            "success": True,
            "blacklisted_urls": count,
            "message": f"{count} URL blacklist'te"
        })
        
    except Exception as e:
        logger.exception("âŒ /blacklist hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@news_bp.route("/unscraped", methods=["GET"])
def get_unscraped():
    """
    ğŸ“‹ HenÃ¼z scrape edilmemiÅŸ haberleri listele
    Debug/monitoring iÃ§in
    """
    try:
        limit = request.args.get('limit', 20, type=int)
        
        articles = NewsModel.get_unscraped(limit=limit)
        
        return jsonify({
            "success": True,
            "count": len(articles),
            "total_unscraped": NewsModel.count_unscraped(),
            "articles": articles
        })
        
    except Exception as e:
        logger.exception("âŒ /unscraped hatasÄ±")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500
```

---

## âœ… **EKLENEN YENÄ° ENDPOINT'LER:**

### **1. Android Ä°Ã§in Ana Endpoint'ler:**
```
GET /api/news/scraped
    âœ… Sadece tam metin haberleri dÃ¶ndÃ¼r
    âœ… Pagination desteÄŸi (limit, offset)
    âœ… Kategori filtresi
    
GET /api/news/scraped/after?after=2025-12-08T15:00:00Z
    âœ… Belirli tarihten sonraki tam metinler
    âœ… Android Worker iÃ§in
    
GET /api/news/scraped/stats
    âœ… Scraping istatistikleri
    âœ… BaÅŸarÄ± oranÄ±
```

### **2. YÃ¶netici/Debug Endpoint'leri:**
```
GET /api/news/blacklist
    âœ… Blacklist sayÄ±sÄ±
    
GET /api/news/unscraped
    âœ… HenÃ¼z scrape edilmemiÅŸ haberler
```

### **3. GÃ¼ncellenmiÅŸ Endpoint'ler:**
```
GET /api/news/status
    âœ… Scraping istatistikleri eklendi
    
GET /api/news/latest
    âš ï¸ ESKÄ° - Geriye dÃ¶nÃ¼k uyumluluk iÃ§in korundu
