from newspaper import Article, Config as NewspaperConfig
from models.news_models import NewsModel
from utils.helpers import full_clean_news_pipeline
import time
import random
import logging
import threading

logger = logging.getLogger(__name__)

# ðŸ¥¸ KILIK DEÄžÄ°ÅžTÄ°RME LÄ°STESÄ° (User-Agents)
# Bu listeyle siteye "Ben Chrome'um", "Ben Firefox'um" diyeceÄŸiz.
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0'
]

def scrape_article_content(url: str):
    """
    Haber URL'sinden tam iÃ§eriÄŸi Ã§eker (GeliÅŸmiÅŸ Ayarlar ile)
    """
    try:
        # Rastgele bir kimlik seÃ§
        user_agent = random.choice(USER_AGENTS)
        
        # Newspaper kÃ¼tÃ¼phanesini kandÄ±rmak iÃ§in ayarlar
        config = NewspaperConfig()
        config.browser_user_agent = user_agent
        config.request_timeout = 15 # 15 saniye bekle
        config.fetch_images = True
        
        article = Article(url, language='tr', config=config)
        article.download()
        article.parse()
        
        full_text = article.text.strip()
        
        # EÄŸer metin Ã§ok kÄ±saysa (mesela 200 karakterden az), muhtemelen hata vermiÅŸtir veya sadece Ã¶zet Ã§ekmiÅŸtir.
        if len(full_text) < 200:
            logger.warning(f"âš ï¸ Ä°Ã§erik Ã§ok kÄ±sa ({len(full_text)} karakter), baÅŸarÄ±sÄ±z sayÄ±ldÄ±: {url}")
            return None, None
        
        scraped_image = article.top_image if article.top_image else None
        
        logger.debug(f"âœ… BaÅŸarÄ±lÄ± Scrape: {len(full_text)} karakter Ã§ekildi.")
        return full_text, scraped_image
        
    except Exception as e:
        logger.error(f"âŒ Scrape hatasÄ± ({url}): {e}")
        return None, None


def scrape_latest_news(count=15):
    """
    En son scrape edilmemiÅŸ haberleri Ã§eker ve veritabanÄ±na kaydeder
    """
    logger.info(f"ðŸ” Scrape edilecek haberler aranÄ±yor... (Hedef: {count})")
    
    pending_articles = NewsModel.get_unscraped(limit=count, exclude_blacklist=True)
    
    if not pending_articles:
        logger.info("âœ… Scrape edilecek haber yok (Hepsi dolu)")
        return
    
    logger.info(f"ðŸ“° {len(pending_articles)} haber iÅŸleme alÄ±ndÄ±...")
    
    success = 0
    failed = 0
    
    for idx, article in enumerate(pending_articles, 1):
        try:
            article_url = article['url']
            article_id = article['id']
            article_title = article.get('title', '')
            
            # Blacklist kontrolÃ¼
            if NewsModel.is_blacklisted(article_url, threshold=3):
                logger.debug(f"ðŸš« Blacklist, atlanÄ±yor: {article_title[:30]}...")
                failed += 1
                continue
            
            logger.info(f"ðŸ”„ [{idx}/{len(pending_articles)}] Ä°ndiriliyor: {article_title[:40]}...")
            
            # Ä°Ã§eriÄŸi scrape et
            full_content, scraped_image = scrape_article_content(article_url)
            
            if full_content:
                # Ä°Ã§eriÄŸi temizle (Gereksiz boÅŸluklarÄ± vs at)
                # Not: helper fonksiyonu yoksa dÃ¼z metni kullanÄ±rÄ±z
                try:
                    cleaned_data = full_clean_news_pipeline(
                        title=article_title,
                        content=full_content,
                        description=article.get('description'),
                        date=article.get('published')
                    )
                    final_content = cleaned_data['content']
                except:
                    final_content = full_content

                # GÃ¶rsel seÃ§imi
                api_image = article.get('image')
                final_image = scraped_image if scraped_image else api_image
                
                # VeritabanÄ±na kaydet
                NewsModel.update_full_content(
                    article_id, 
                    final_content, 
                    final_image
                )
                
                success += 1
                logger.info(f"   âœ… KAYDEDÄ°LDÄ°: {len(final_content)} karakter.")
            else:
                failed += 1
                NewsModel.add_to_blacklist(article_url, reason="content_empty")
                logger.warning(f"   âš ï¸ Ä°Ã§erik boÅŸ dÃ¶ndÃ¼, pas geÃ§ildi.")
            
            # â³ Site bizi engellemesin diye azÄ±cÄ±k bekle (1-3 saniye)
            time.sleep(random.uniform(1.0, 3.0))
            
        except Exception as e:
            failed += 1
            logger.error(f"   âŒ Kritik Hata: {e}")
    
    logger.info(f"ðŸŽ‰ Scraping Turu Bitti! BaÅŸarÄ±lÄ±: {success}, BaÅŸarÄ±sÄ±z: {failed}")

def scrape_in_background(count=15):
    """Arka planda Ã§alÄ±ÅŸtÄ±r"""
    thread = threading.Thread(target=scrape_latest_news, args=(count,), daemon=True)
    thread.start()
