"""
Habersel Backend - YardÄ±mcÄ± Fonksiyonlar
=========================================

Bu modÃ¼l genel amaÃ§lÄ± yardÄ±mcÄ± fonksiyonlar iÃ§erir:
- Timezone dÃ¶nÃ¼ÅŸÃ¼mleri
- String iÅŸlemleri
- Validation (doÄŸrulama)
- Retry mekanizmasÄ±
- Haber iÃ§erik temizleme (YENÄ°)
- DiÄŸer utility fonksiyonlar
"""

import re
import time
import logging
from datetime import datetime, timedelta
from typing import Optional, Callable, Any
from functools import wraps
import pytz
from config import Config

logger = logging.getLogger(__name__)

# ============================================
# 1ï¸âƒ£ TIMEZONE DÃ–NÃœÅÃœM FONKSÄ°YONLARI
# ============================================

def get_local_timezone():
    """TÃ¼rkiye saat dilimini dÃ¶ndÃ¼rÃ¼r"""
    return pytz.timezone(Config.TIMEZONE)


def utc_to_local(utc_time: datetime) -> datetime:
    """
    UTC zamanÄ±nÄ± TÃ¼rkiye saatine Ã§evirir
    
    Args:
        utc_time: UTC datetime objesi
    
    Returns:
        TÃ¼rkiye saatinde datetime
    """
    if utc_time.tzinfo is None:
        utc_time = pytz.utc.localize(utc_time)
    
    local_tz = get_local_timezone()
    return utc_time.astimezone(local_tz)


def local_to_utc(local_time: datetime) -> datetime:
    """
    TÃ¼rkiye saatini UTC'ye Ã§evirir
    
    Args:
        local_time: TÃ¼rkiye saatinde datetime
    
    Returns:
        UTC datetime
    """
    local_tz = get_local_timezone()
    
    if local_time.tzinfo is None:
        local_time = local_tz.localize(local_time)
    
    return local_time.astimezone(pytz.utc)


def parse_datetime(date_str: str) -> Optional[datetime]:
    """
    Ã‡eÅŸitli formatlardaki tarih string'ini datetime'a Ã§evirir
    
    Desteklenen formatlar:
    - ISO 8601: "2025-11-30T14:30:00Z"
    - RFC 2822: "Sat, 30 Nov 2025 14:30:00 GMT"
    - Timestamp: "1732976400"
    
    Args:
        date_str: Tarih string'i
    
    Returns:
        datetime objesi veya None
    """
    if not date_str:
        return None
    
    # ISO 8601 format
    try:
        # Z'yi +00:00'a Ã§evir
        normalized = date_str.replace("Z", "+00:00")
        return datetime.fromisoformat(normalized)
    except (ValueError, AttributeError):
        pass
    
    # Unix timestamp
    try:
        timestamp = float(date_str)
        return datetime.fromtimestamp(timestamp, tz=pytz.utc)
    except (ValueError, TypeError):
        pass
    
    # dateutil ile diÄŸer formatlar (opsiyonel)
    try:
        from dateutil import parser
        return parser.parse(date_str)
    except ImportError:
        logger.warning("dateutil paketi yok, bazÄ± tarih formatlarÄ± parse edilemeyebilir")
    except Exception:
        pass
    
    logger.warning(f"âš ï¸ Tarih parse edilemedi: {date_str}")
    return None


def get_time_ago(timestamp: datetime) -> str:
    """
    Verilen zamanÄ±n ÅŸimdiden ne kadar Ã¶nce olduÄŸunu hesaplar
    
    Args:
        timestamp: datetime objesi
    
    Returns:
        "5 dakika Ã¶nce", "3 saat Ã¶nce", "2 gÃ¼n Ã¶nce" formatÄ±nda string
    """
    now = datetime.now(pytz.utc)
    
    # Timezone kontrolÃ¼
    if timestamp.tzinfo is None:
        timestamp = pytz.utc.localize(timestamp)
    
    diff = now - timestamp
    seconds = diff.total_seconds()
    
    if seconds < 0:
        return "gelecekte"
    
    if seconds < 60:
        return "az Ã¶nce"
    
    if seconds < 3600:  # 1 saat
        minutes = int(seconds / 60)
        return f"{minutes} dakika Ã¶nce"
    
    if seconds < 86400:  # 1 gÃ¼n
        hours = int(seconds / 3600)
        return f"{hours} saat Ã¶nce"
    
    if seconds < 604800:  # 1 hafta
        days = int(seconds / 86400)
        return f"{days} gÃ¼n Ã¶nce"
    
    if seconds < 2592000:  # 30 gÃ¼n
        weeks = int(seconds / 604800)
        return f"{weeks} hafta Ã¶nce"
    
    # 30 gÃ¼nden eski ise tarih gÃ¶ster
    return format_date(timestamp, format_type="short")


def format_date(dt: datetime, format_type: str = "full") -> str:
    """
    Tarihi okunabilir formatta dÃ¶ndÃ¼rÃ¼r
    
    Args:
        dt: datetime objesi
        format_type: "full", "short", "time_only"
    
    Returns:
        FormatlanmÄ±ÅŸ tarih string'i
    """
    if dt.tzinfo is None:
        dt = pytz.utc.localize(dt)
    
    # TÃ¼rkiye saatine Ã§evir
    local_dt = utc_to_local(dt)
    
    if format_type == "full":
        # "30 KasÄ±m 2025, Pazar 14:30"
        return local_dt.strftime("%d %B %Y, %A %H:%M")
    
    elif format_type == "short":
        # "30 Kas 2025"
        return local_dt.strftime("%d %b %Y")
    
    elif format_type == "time_only":
        # "14:30"
        return local_dt.strftime("%H:%M")
    
    else:
        # Default: ISO format
        return local_dt.isoformat()


# ============================================
# 2ï¸âƒ£ STRING YARDIMCI FONKSÄ°YONLARI
# ============================================

def clean_text(text: str) -> str:
    """
    Metni temizler ve normalize eder
    
    - Extra boÅŸluklarÄ± kaldÄ±rÄ±r
    - BaÅŸÄ±ndaki/sonundaki boÅŸluklarÄ± atar
    - Ã‡ift boÅŸluklarÄ± tek yapar
    - SatÄ±r baÅŸÄ±/sonu karakterlerini temizler
    
    Args:
        text: Temizlenecek metin
    
    Returns:
        TemizlenmiÅŸ metin
    """
    if not text:
        return ""
    
    # SatÄ±r baÅŸÄ±/sonu karakterlerini kaldÄ±r
    text = text.replace("\n", " ").replace("\r", " ").replace("\t", " ")
    
    # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa indir
    text = " ".join(text.split())
    
    # BaÅŸÄ±ndaki ve sonundaki boÅŸluklarÄ± at
    text = text.strip()
    
    return text


def truncate_text(text: str, max_length: int = 100, suffix: str = "...") -> str:
    """
    Metni belirli uzunlukta keser
    
    Args:
        text: Kesilecek metin
        max_length: Maksimum uzunluk
        suffix: Sona eklenecek (varsayÄ±lan: "...")
    
    Returns:
        KÄ±saltÄ±lmÄ±ÅŸ metin
    """
    if not text:
        return ""
    
    if len(text) <= max_length:
        return text
    
    # Son kelimeyi bÃ¶lmemek iÃ§in son boÅŸluÄŸa kadar kes
    truncated = text[:max_length].rsplit(" ", 1)[0]
    return truncated + suffix


def remove_html_tags(text: str) -> str:
    """
    HTML tag'lerini temizler
    
    Args:
        text: HTML iÃ§eren metin
    
    Returns:
        Sadece dÃ¼z metin
    """
    if not text:
        return ""
    
    # HTML tag'lerini kaldÄ±r
    clean = re.sub(r'<[^>]+>', '', text)
    
    # HTML entity'leri decode et
    clean = clean.replace("&nbsp;", " ")
    clean = clean.replace("&amp;", "&")
    clean = clean.replace("&lt;", "<")
    clean = clean.replace("&gt;", ">")
    clean = clean.replace("&quot;", '"')
    clean = clean.replace("&#39;", "'")
    
    return clean_text(clean)


def remove_emojis(text: str) -> str:
    """
    Emoji'leri kaldÄ±rÄ±r
    
    Args:
        text: Emoji iÃ§eren metin
    
    Returns:
        Emoji'siz metin
    """
    if not text:
        return ""
    
    # Emoji regex pattern
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # emoticons
        "\U0001F300-\U0001F5FF"  # symbols & pictographs
        "\U0001F680-\U0001F6FF"  # transport & map symbols
        "\U0001F1E0-\U0001F1FF"  # flags
        "\U00002702-\U000027B0"
        "\U000024C2-\U0001F251"
        "]+",
        flags=re.UNICODE
    )
    
    return emoji_pattern.sub('', text)


def sanitize_filename(filename: str) -> str:
    """
    Dosya adÄ±nÄ± gÃ¼venli hale getirir
    
    Args:
        filename: Dosya adÄ±
    
    Returns:
        GÃ¼venli dosya adÄ±
    """
    if not filename:
        return "unnamed"
    
    # Ã–zel karakterleri kaldÄ±r
    safe = re.sub(r'[<>:"/\\|?*]', '', filename)
    
    # BoÅŸluklarÄ± alt Ã§izgi yap
    safe = safe.replace(" ", "_")
    
    # TÃ¼rkÃ§e karakterleri dÃ¼zelt
    turkish_map = {
        'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
        'Ã‡': 'C', 'Ä': 'G', 'Ä°': 'I', 'Ã–': 'O', 'Å': 'S', 'Ãœ': 'U'
    }
    
    for turkish, english in turkish_map.items():
        safe = safe.replace(turkish, english)
    
    return safe.lower()


def extract_domain(url: str) -> Optional[str]:
    """
    URL'den domain adÄ±nÄ± Ã§Ä±karÄ±r
    
    Args:
        url: URL string'i
    
    Returns:
        Domain adÄ± (Ã¶rn: "example.com")
    """
    if not url:
        return None
    
    # Protocol'Ã¼ kaldÄ±r
    domain = url.replace("https://", "").replace("http://", "")
    
    # www. kaldÄ±r
    domain = domain.replace("www.", "")
    
    # Path'i kaldÄ±r
    domain = domain.split("/")[0]
    
    # Port numarasÄ±nÄ± kaldÄ±r
    domain = domain.split(":")[0]
    
    return domain.lower()


# ============================================
# ğŸ†• HABER Ä°Ã‡ERÄ°K TEMÄ°ZLEME FONKSÄ°YONLARI
# ============================================

def clean_news_content(content: Optional[str]) -> Optional[str]:
    """
    Haber iÃ§eriÄŸini temizler ve dÃ¼zenler
    
    ğŸ§¹ Temizleme iÅŸlemleri:
    - "Haberin DevamÄ±", "GÃ¶zden KaÃ§masÄ±n" gibi kalÄ±plarÄ± siler
    - Twitter embed artÄ±klarÄ±nÄ± (t.co linkleri, kullanÄ±cÄ± adlarÄ±) kaldÄ±rÄ±r
    - Hashtagleri temizler
    - Ã‡ift boÅŸluklarÄ± dÃ¼zeltir
    - ParagraflarÄ± dÃ¼zenler
    - TÃ¼rkÃ§e karakter hatalarÄ±nÄ± dÃ¼zeltir
    
    Args:
        content: Ham haber metni
        
    Returns:
        TemizlenmiÅŸ ve dÃ¼zenlenmiÅŸ metin
    """
    if not content:
        return None
    
    text = content
    
    # 1ï¸âƒ£ Gereksiz kalÄ±plarÄ± sil
    remove_patterns = [
        r"Haberin DevamÄ±[:\s]*",
        r"GÃ¶zden KaÃ§masÄ±n[:\s]*",
        r"Haberi gÃ¶rÃ¼ntÃ¼le[:\s]*",
        r"Ä°lgili Haber[:\s]*",
        r"Ã–nerilen Haber[:\s]*",
        r"DevamÄ±nÄ± Oku[:\s]*",
        r"TÄ±klayÄ±nÄ±z[:\s]*",
        r"Kaynak\s*:\s*\w+",
        r"EditÃ¶r\s*:\s*\w+",
        r"https?://t\.co/\w+",  # Twitter kÄ±sa linkleri
        r"â€”\s*@\w+\s+\([^)]+\)",  # Twitter kullanÄ±cÄ± adlarÄ± (â€” @user (date))
        r"@\w+",  # DiÄŸer mention'lar
        r"#[\wÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄÃœÅÄ°Ã–Ã‡]+",  # Hashtagler (TÃ¼rkÃ§e karakterli)
        r"\[.*?\]",  # KÃ¶ÅŸeli parantez iÃ§i metinler
        r"\(FotoÄŸraf:.*?\)",  # FotoÄŸraf notlarÄ±
        r"\(Foto:.*?\)",
        r"Ä°lan\s*\d+",  # Ä°lan numaralarÄ±
        r"Reklam\s*\d*",
    ]
    
    for pattern in remove_patterns:
        text = re.sub(pattern, "", text, flags=re.IGNORECASE)
    
    # 2ï¸âƒ£ HTML tag'lerini temizle
    text = remove_html_tags(text)
    
    # 3ï¸âƒ£ Ã‡ift boÅŸluklarÄ± tek boÅŸluÄŸa indir
    text = re.sub(r' +', ' ', text)
    
    # 4ï¸âƒ£ Ã‡oklu satÄ±r sonlarÄ±nÄ± dÃ¼zenle (3+ boÅŸ satÄ±r â†’ 2 boÅŸ satÄ±r)
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    
    # 5ï¸âƒ£ BaÅŸ ve son boÅŸluklarÄ± temizle
    text = text.strip()
    
    # 6ï¸âƒ£ ParagraflarÄ± dÃ¼zenle (uzun paragraflarÄ± bÃ¶l)
    paragraphs = text.split('\n\n')
    formatted_paragraphs = []
    
    for para in paragraphs:
        para = para.strip()
        if not para or len(para) < 10:  # Ã‡ok kÄ±sa satÄ±rlarÄ± atla
            continue
        
        # Ã‡ok uzun paragraflarÄ± bÃ¶l (5+ cÃ¼mle varsa)
        sentences = re.split(r'(?<=[.!?])\s+', para)
        
        if len(sentences) > 5:
            # Her 3-4 cÃ¼mleyi yeni paragrafa dÃ¶nÃ¼ÅŸtÃ¼r
            temp_para = []
            for i, sentence in enumerate(sentences):
                temp_para.append(sentence)
                if (i + 1) % 4 == 0 and i < len(sentences) - 1:
                    formatted_paragraphs.append(' '.join(temp_para))
                    temp_para = []
            if temp_para:
                formatted_paragraphs.append(' '.join(temp_para))
        else:
            formatted_paragraphs.append(para)
    
    # 7ï¸âƒ£ ParagraflarÄ± birleÅŸtir
    result = '\n\n'.join(formatted_paragraphs)
    
    # 8ï¸âƒ£ TÃ¼rkÃ§e karakter dÃ¼zeltmeleri (encoding hatalarÄ±)
    turkish_fixes = {
        'Ã„Â±': 'Ä±', 'Ã„Â°': 'Ä°',
        'Ã…Å¾': 'Å', 'Ã…Å¸': 'ÅŸ',
        'ÃƒÂ§': 'Ã§', 'Ãƒâ€¡': 'Ã‡',
        'ÃƒÂ¶': 'Ã¶', 'Ãƒâ€“': 'Ã–',
        'ÃƒÂ¼': 'Ã¼', 'ÃƒÅ“': 'Ãœ',
        'Ã„Å¸': 'ÄŸ', 'Ã„': 'Ä',
    }
    
    for wrong, correct in turkish_fixes.items():
        result = result.replace(wrong, correct)
    
    # 9ï¸âƒ£ BoÅŸ satÄ±rlarÄ± temizle
    lines = result.split('\n')
    lines = [line.strip() for line in lines if line.strip()]
    result = '\n\n'.join(lines)
    
    return result if result else None


def clean_news_title(title: Optional[str]) -> Optional[str]:
    """
    Haber baÅŸlÄ±ÄŸÄ±nÄ± temizler
    
    Args:
        title: Ham baÅŸlÄ±k
        
    Returns:
        TemizlenmiÅŸ baÅŸlÄ±k
    """
    if not title:
        return None
    
    text = title.strip()
    
    # Gereksiz kalÄ±plarÄ± sil
    text = re.sub(r'\[.*?\]', '', text)  # [Ã–zel Haber] gibi etiketler
    text = re.sub(r'\(.*?\)', '', text)  # (Videolu) gibi notlar
    text = re.sub(r'#[\wÄŸÃ¼ÅŸÄ±Ã¶Ã§ÄÃœÅÄ°Ã–Ã‡]+', '', text)  # Hashtagler
    
    # HTML tag'lerini temizle
    text = remove_html_tags(text)
    
    # Ã‡ift boÅŸluklarÄ± dÃ¼zelt
    text = re.sub(r'\s+', ' ', text)
    
    # TÃ¼rkÃ§e karakter dÃ¼zeltmeleri
    turkish_fixes = {
        'Ã„Â±': 'Ä±', 'Ã„Â°': 'Ä°',
        'Ã…Å¾': 'Å', 'Ã…Å¸': 'ÅŸ',
        'ÃƒÂ§': 'Ã§', 'Ãƒâ€¡': 'Ã‡',
        'ÃƒÂ¶': 'Ã¶', 'Ãƒâ€“': 'Ã–',
        'ÃƒÂ¼': 'Ã¼', 'ÃƒÅ“': 'Ãœ',
        'Ã„Å¸': 'ÄŸ', 'Ã„': 'Ä',
    }
    
    for wrong, correct in turkish_fixes.items():
        text = text.replace(wrong, correct)
    
    # BaÅŸlÄ±k Ã§ok uzunsa kÄ±salt (150 karakterden uzun olmamalÄ±)
    if len(text) > 150:
        text = text[:147] + "..."
    
    return text.strip() if text.strip() else None


def format_news_date(date_str: Optional[str]) -> Optional[str]:
    """
    Haber tarihini dd.MM.yyyy formatÄ±na Ã§evirir
    
    Args:
        date_str: Ham tarih string (ISO format veya baÅŸka)
        
    Returns:
        dd.MM.yyyy formatÄ±nda tarih (Ã¶rn: "07.12.2025")
    """
    if not date_str:
        return None
    
    try:
        # ISO format deneme
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        return dt.strftime('%d.%m.%Y')
    except:
        pass
    
    try:
        # DiÄŸer formatlar
        dt = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
        return dt.strftime('%d.%m.%Y')
    except:
        pass
    
    # Parse edilemezse orijinali dÃ¶ndÃ¼r
    return date_str


def detect_and_format_subheadings(content: str) -> str:
    """
    Ä°Ã§erikteki alt baÅŸlÄ±klarÄ± algÄ±lar ve bold formatlar
    
    AlgÄ±lama kurallarÄ±:
    - Tamamen bÃ¼yÃ¼k harfli ve 100 karakterden kÄ±sa satÄ±rlar
    - 15 kelimeden az olan satÄ±rlar
    
    Args:
        content: Haber iÃ§eriÄŸi
        
    Returns:
        Alt baÅŸlÄ±klarÄ± **bold** formatÄ±nda iÅŸaretlenmiÅŸ iÃ§erik
    """
    if not content:
        return ""
    
    lines = content.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            formatted_lines.append('')
            continue
        
        # Tamamen bÃ¼yÃ¼k harfli ve kÄ±sa satÄ±rlarÄ± alt baÅŸlÄ±k olarak iÅŸaretle
        word_count = len(line.split())
        is_all_caps = line.isupper()
        is_short = len(line) < 100 and word_count < 15
        
        if is_all_caps and is_short and word_count > 2:
            # Title case yap ve bold iÅŸaretle
            formatted_lines.append(f"**{line.title()}**")
        else:
            formatted_lines.append(line)
    
    return '\n'.join(formatted_lines)


def remove_duplicate_paragraphs(text: str) -> str:
    """
    Tekrar eden paragraflarÄ±/cÃ¼mleleri kaldÄ±rÄ±r
    
    Args:
        text: Haber metni
        
    Returns:
        TekrarlarÄ± kaldÄ±rÄ±lmÄ±ÅŸ metin
    """
    if not text:
        return ""
    
    paragraphs = text.split('\n\n')
    seen = set()
    unique_paragraphs = []
    
    for para in paragraphs:
        para_clean = para.strip().lower()
        if para_clean and para_clean not in seen and len(para_clean) > 20:
            seen.add(para_clean)
            unique_paragraphs.append(para.strip())
    
    return '\n\n'.join(unique_paragraphs)


def full_clean_news_pipeline(
    title: str,
    content: Optional[str],
    description: Optional[str] = None,
    date: Optional[str] = None
) -> dict:
    """
    ğŸ¯ TAM TEMÄ°ZLEME PÄ°PELINE - TÃ¼m iÅŸlemleri birleÅŸtirir
    
    Bu fonksiyonu scraping sÄ±rasÄ±nda kullan!
    
    Args:
        title: Ham baÅŸlÄ±k
        content: Ham tam iÃ§erik (full_content)
        description: Ham Ã¶zet/aÃ§Ä±klama
        date: Ham tarih
        
    Returns:
        TemizlenmiÅŸ veri dict'i:
        {
            'title': 'Temiz baÅŸlÄ±k',
            'content': 'Temiz tam iÃ§erik',
            'description': 'Temiz Ã¶zet',
            'date': '07.12.2025'
        }
    """
    cleaned_title = clean_news_title(title)
    
    # Ä°Ã§eriÄŸi tamamen temizle
    if content:
        cleaned_content = clean_news_content(content)
        if cleaned_content:
            cleaned_content = remove_duplicate_paragraphs(cleaned_content)
            cleaned_content = detect_and_format_subheadings(cleaned_content)
    else:
        cleaned_content = None
    
    # Description'Ä± temizle
    if description:
        cleaned_desc = clean_news_content(description)
        # Description Ã§ok uzunsa kÄ±salt (500 karakter)
        if cleaned_desc and len(cleaned_desc) > 500:
            cleaned_desc = cleaned_desc[:497] + "..."
    else:
        cleaned_desc = None
    
    # Tarihi formatla
    formatted_date = format_news_date(date)
    
    return {
        'title': cleaned_title,
        'content': cleaned_content,
        'description': cleaned_desc,
        'date': formatted_date
    }


# ============================================
# 3ï¸âƒ£ VALIDATION (DOÄRULAMA) FONKSÄ°YONLARI
# ============================================

def is_valid_url(url: str) -> bool:
    """
    URL formatÄ±nÄ±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    
    Args:
        url: Kontrol edilecek URL
    
    Returns:
        GeÃ§erli ise True
    """
    if not url or not isinstance(url, str):
        return False
    
    # Basit URL regex
    url_pattern = re.compile(
        r'^https?://'  # http:// veya https://
        r'(?:(?:[A-Z0-9](?:[A-Z0-9-]{0,61}[A-Z0-9])?\.)+[A-Z]{2,6}\.?|'  # domain
        r'localhost|'  # localhost
        r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})'  # IP
        r'(?::\d+)?'  # port (opsiyonel)
        r'(?:/?|[/?]\S+)$',  # path
        re.IGNORECASE
    )
    
    return bool(url_pattern.match(url))


def is_valid_email(email: str) -> bool:
    """
    Email formatÄ±nÄ±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    
    Args:
        email: Kontrol edilecek email
    
    Returns:
        GeÃ§erli ise True
    """
    if not email or not isinstance(email, str):
        return False
    
    email_pattern = re.compile(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$')
    return bool(email_pattern.match(email))


def is_valid_article(article: dict) -> bool:
    """
    Haber verisinin geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    
    Gerekli alanlar:
    - title (boÅŸ olmamalÄ±)
    - url (geÃ§erli URL formatÄ±nda)
    
    Args:
        article: Haber dict'i
    
    Returns:
        GeÃ§erli ise True
    """
    if not article or not isinstance(article, dict):
        return False
    
    # Title kontrolÃ¼
    title = article.get("title", "").strip()
    if not title or len(title) < 5:
        logger.debug("âš ï¸ GeÃ§ersiz haber: BaÅŸlÄ±k yok veya Ã§ok kÄ±sa")
        return False
    
    # URL kontrolÃ¼
    url = article.get("url", "").strip()
    if not is_valid_url(url):
        logger.debug("âš ï¸ GeÃ§ersiz haber: URL formatÄ± hatalÄ±")
        return False
    
    return True


def sanitize_url(url: str) -> str:
    """
    URL'i dÃ¼zeltir ve normalize eder
    
    - http â†’ https yapar
    - www. ekler (yoksa)
    - Trailing slash ekler
    
    Args:
        url: DÃ¼zeltilecek URL
    
    Returns:
        DÃ¼zeltilmiÅŸ URL
    """
    if not url:
        return ""
    
    url = url.strip()
    
    # http â†’ https
    if url.startswith("http://"):
        url = url.replace("http://", "https://", 1)
    
    # https:// yoksa ekle
    if not url.startswith("https://"):
        url = "https://" + url
    
    return url


def validate_category(category: str) -> bool:
    """
    Kategori adÄ±nÄ±n geÃ§erli olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
    
    Args:
        category: Kategori adÄ±
    
    Returns:
        GeÃ§erli ise True
    """
    if not category:
        return False
    
    return category.lower() in [c.lower() for c in Config.NEWS_CATEGORIES]


# ============================================
# 4ï¸âƒ£ RETRY DECORATOR (TEKRAR DENEME)
# ============================================

def retry(
    max_attempts: int = 3,
    delay: float = 2.0,
    backoff: float = 2.0,
    exceptions: tuple = (Exception,)
):
    """
    Fonksiyonu hata durumunda otomatik tekrar dener
    
    Args:
        max_attempts: Maksimum deneme sayÄ±sÄ±
        delay: Ä°lk bekleme sÃ¼resi (saniye)
        backoff: Her denemede bekleme sÃ¼resini Ã§arpan
        exceptions: Yakalanacak exception tÃ¼rleri
    
    Usage:
        @retry(max_attempts=3, delay=2)
        def fetch_api():
            return requests.get("https://api.example.com")
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            attempt = 0
            current_delay = delay
            
            while attempt < max_attempts:
                try:
                    return func(*args, **kwargs)
                    
                except exceptions as e:
                    attempt += 1
                    
                    if attempt >= max_attempts:
                        logger.error(
                            f"âŒ {func.__name__} baÅŸarÄ±sÄ±z oldu "
                            f"({max_attempts} deneme sonrasÄ±): {e}"
                        )
                        raise
                    
                    logger.warning(
                        f"âš ï¸ {func.__name__} baÅŸarÄ±sÄ±z (deneme {attempt}/{max_attempts}), "
                        f"{current_delay:.1f}s bekleniyor... Hata: {e}"
                    )
                    
                    time.sleep(current_delay)
                    current_delay *= backoff
            
        return wrapper
    return decorator


# ============================================
# 5ï¸âƒ£ DÄ°ÄER YARDIMCI FONKSÄ°YONLAR
# ============================================

def safe_dict_get(data: dict, *keys, default=None):
    """
    Ä°Ã§ iÃ§e dict'ten gÃ¼venli ÅŸekilde veri alÄ±r
    
    Args:
        data: Ana dict
        keys: Ä°Ã§ iÃ§e key'ler
        default: Bulunamazsa dÃ¶ndÃ¼rÃ¼lecek deÄŸer
    
    Returns:
        Bulunan deÄŸer veya default
    
    Example:
        data = {"user": {"profile": {"name": "Ali"}}}
        name = safe_dict_get(data, "user", "profile", "name")
        # "Ali"
    """
    current = data
    
    for key in keys:
        if isinstance(current, dict):
            current = current.get(key)
            if current is None:
                return default
        else:
            return default
    
    return current if current is not None else default


def chunk_list(lst: list, chunk_size: int) -> list:
    """
    Listeyi belirli boyutta parÃ§alara bÃ¶ler
    
    Args:
        lst: BÃ¶lÃ¼necek liste
        chunk_size: ParÃ§a boyutu
    
    Returns:
        ParÃ§alara bÃ¶lÃ¼nmÃ¼ÅŸ liste
    
    Example:
        chunk_list([1,2,3,4,5], 2)
        # [[1,2], [3,4], [5]]
    """
    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]


def generate_unique_id() -> str:
    """
    Benzersiz ID Ã¼retir (timestamp bazlÄ±)
    
    Returns:
        Unique ID string'i
    """
    import uuid
    return str(uuid.uuid4())


def bytes_to_human_readable(bytes_size: int) -> str:
    """
    Byte'Ä± okunabilir formata Ã§evirir
    
    Args:
        bytes_size: Byte cinsinden boyut
    
    Returns:
        "1.5 MB", "250 KB" formatÄ±nda string
    """
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.1f} PB"


def mask_sensitive_data(text: str, mask_char: str = "*") -> str:
    """
    Hassas veriyi maskeler (API key, ÅŸifre vb.)
    
    Args:
        text: Maskelenecek metin
        mask_char: Maskeleme karakteri
    
    Returns:
        Ä°lk 4 ve son 4 karakter hariÃ§ maskeli metin
    
    Example:
        mask_sensitive_data("sk_1234567890abcdef")
        # "sk_1***********cdef"
    """
    if not text or len(text) <= 8:
        return mask_char * len(text)
    
    visible_chars = 4
    masked_section = mask_char * (len(text) - 2 * visible_chars)
    
    return text[:visible_chars] + masked_section + text[-visible_chars:]


def calculate_percentage(part: float, total: float) -> float:
    """
    YÃ¼zde hesaplar
    
    Args:
        part: KÄ±sÄ±m
        total: Toplam
    
    Returns:
        YÃ¼zde deÄŸeri (0-100)
    """
    if total == 0:
        return 0.0
    
    return round((part / total) * 100, 2)
